{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff855fd8-14db-4260-a2aa-f3f6194b9e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DeFooocus] Preparing ...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/content\n",
            "Cloning into 'DeFooocus'...\n",
            "remote: Enumerating objects: 7029, done.\u001b[K\n",
            "remote: Total 7029 (delta 0), reused 0 (delta 0), pack-reused 7029 (from 1)\u001b[K\n",
            "Receiving objects: 100% (7029/7029), 47.33 MiB | 15.16 MiB/s, done.\n",
            "Resolving deltas: 100% (3838/3838), done.\n",
            "/content/DeFooocus\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.9/757.9 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.4/33.4 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.8/827.8 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.7/54.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.6/130.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for groundingdino-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyExecJS (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
            "dataproc-spark-connect 0.7.3 requires tqdm>=4.67, but you have tqdm 4.65.0 which is incompatible.\n",
            "dataproc-spark-connect 0.7.3 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "google-genai 1.14.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.24.1 which is incompatible.\n",
            "google-genai 1.14.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "albumentations 2.0.6 requires scipy>=1.10.0, but you have scipy 1.9.3 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.9.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "stumpy 1.13.0 requires scipy>=1.10, but you have scipy 1.9.3 which is incompatible.\n",
            "datasets 2.14.4 requires dill<0.3.8,>=0.3.0, but you have dill 0.4.0 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, but you have scipy 1.9.3 which is incompatible.\n",
            "jax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.9.3 which is incompatible.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.30.2 which is incompatible.\n",
            "cvxpy 1.6.5 requires scipy>=1.11.0, but you have scipy 1.9.3 which is incompatible.\n",
            "torchtune 0.6.1 requires Pillow>=9.4.0, but you have pillow 9.2.0 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m[DeFooocus] Starting ...\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--attention-split', '--always-high-vram', '--disable-offload-from-vram', '--all-in-fp16', '--theme', 'dark']\n",
            "Python 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "Fooocus version: 0.2\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/DeFooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 86.5MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/DeFooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 31.5MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xl-to-v1_interposer-v3.1.safetensors\" to /content/DeFooocus/models/vae_approx/xl-to-v1_interposer-v3.1.safetensors\n",
            "\n",
            "100% 6.25M/6.25M [00:00<00:00, 340MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/DeFooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:00<00:00, 383MB/s]\n",
            "Downloading: \"https://huggingface.co/fluently/Fluently-XL-v4/resolve/main/FluentlyXL-v4.safetensors\" to /content/DeFooocus/models/checkpoints/FluentlyXL-v4.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:38<00:00, 185MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/DeFooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 346MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12978 MB\n",
            "Forcing FP16.\n",
            "Set vram state to: HIGH_VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using split optimization for cross attention\n",
            "2025-05-14 10:57:21.722119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747220242.046644    1408 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747220242.133506    1408 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using split attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using split attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/DeFooocus/models/checkpoints/FluentlyXL-v4.safetensors\n",
            "Request to load LoRAs [['sd_xl_offset_example-lora_1.0.safetensors', 0.1], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/DeFooocus/models/checkpoints/FluentlyXL-v4.safetensors].\n",
            "Loaded LoRA [/content/DeFooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/DeFooocus/models/checkpoints/FluentlyXL-v4.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "theme_schema%400.0.1.json: 100% 13.7k/13.7k [00:00<00:00, 46.7MB/s]\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "Running on public URL: https://2baa6705ce9e110fe5.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.67 seconds\n",
            "/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  torch.utils._pytree._register_pytree_node(\n",
            "Started worker with PID 1408\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://2baa6705ce9e110fe5.gradio.live\n",
            "Loaded preset: /content/DeFooocus/presets/anime.json\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/animaPencilXL_v100.safetensors\" to /content/DeFooocus/models/checkpoints/animaPencilXL_v100.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:49<00:00, 63.5MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/dpo.json\n",
            "Downloading: \"https://huggingface.co/ehristoforu/dpo-spo-loras/resolve/main/sd_xl_dpo_lora.safetensors\" to /content/DeFooocus/models/loras/sd_xl_dpo_lora.safetensors\n",
            "\n",
            "100% 751M/751M [00:11<00:00, 70.7MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/dpo.json\n",
            "Loaded preset: /content/DeFooocus/presets/anime.json\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 7.0\n",
            "[Parameters] Seed = 6516819217775534317\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 45 - 22\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using split attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using split attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/DeFooocus/models/checkpoints/animaPencilXL_v100.safetensors\n",
            "Request to load LoRAs [['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/DeFooocus/models/checkpoints/animaPencilXL_v100.safetensors].\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.23 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] دختر لخت کمسن کخ بدنش کامل در دید مخاطب شهوتی قرار دارد و در حال آه و ناله میباشد, highly detailed, excellent composition, cinematic atmosphere, dynamic dramatic epic, beautiful light, aesthetic, very inspirational, perfect, colorful, artistic, winning fine, best, surreal, unique, inspiring, wonderful, creative, positive, lively, elegant, professional, thought, cute, magical, mystical, marvelous, enchanted, exquisite\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1152, 896)\n",
            "Preparation time: 48.04 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 2\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.90 seconds\n",
            "100% 45/45 [01:20<00:00,  1.79s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.12 seconds\n",
            "Image generated with private log at: /content/DeFooocus/outputs/2025-05-14/log.html\n",
            "Generating and saving time: 84.08 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 132.15 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.64 seconds\n",
            "Loaded preset: /content/DeFooocus/presets/realistic.json\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/realisticStockPhoto_v20.safetensors\" to /content/DeFooocus/models/checkpoints/realisticStockPhoto_v20.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [02:35<00:00, 44.7MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/SDXL_FILM_PHOTOGRAPHY_STYLE_BetaV0.4.safetensors\" to /content/DeFooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_BetaV0.4.safetensors\n",
            "\n",
            "100% 222M/222M [00:05<00:00, 39.2MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/lightning.json\n",
            "Downloading: \"https://huggingface.co/ByteDance/SDXL-Lightning/resolve/main/sdxl_lightning_4step_lora.safetensors\" to /content/DeFooocus/models/loras/sdxl_lightning_4step_lora.safetensors\n",
            "\n",
            "100% 376M/376M [00:01<00:00, 275MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/dpo.json\n",
            "Loaded preset: /content/DeFooocus/presets/lightning.json\n",
            "Loaded preset: /content/DeFooocus/presets/hypersd.json\n",
            "Downloading: \"https://huggingface.co/ByteDance/Hyper-SD/resolve/main/Hyper-SDXL-4steps-lora.safetensors\" to /content/DeFooocus/models/loras/Hyper-SDXL-4steps-lora.safetensors\n",
            "\n",
            "100% 751M/751M [00:11<00:00, 67.8MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/turbo.json\n",
            "Downloading: \"https://huggingface.co/Lykon/dreamshaper-xl-turbo/resolve/main/DreamShaperXL_Turbo_dpmppSdeKarras_half_pruned_6.safetensors\" to /content/DeFooocus/models/checkpoints/DreamShaperXL_Turbo_dpmppSdeKarras_half_pruned_6.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:51<00:00, 62.2MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/lightning.json\n",
            "Loaded preset: /content/DeFooocus/presets/spo.json\n",
            "Downloading: \"https://huggingface.co/ehristoforu/dpo-spo-loras/resolve/main/sd_xl_spo_lora.safetensors\" to /content/DeFooocus/models/loras/sd_xl_spo_lora.safetensors\n",
            "\n",
            "100% 355M/355M [00:05<00:00, 74.1MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/spo.json\n",
            "Loaded preset: /content/DeFooocus/presets/default.json\n",
            "Loaded preset: /content/DeFooocus/presets/sd1.5.json\n",
            "Downloading: \"https://huggingface.co/XpucT/Reliberate/resolve/main/Reliberate_v3.safetensors\" to /content/DeFooocus/models/checkpoints/Reliberate_v3.safetensors\n",
            "\n",
            "100% 1.99G/1.99G [00:22<00:00, 94.2MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/playground_v2.5.json\n",
            "Downloading: \"https://huggingface.co/mashb1t/fav_models/resolve/main/fav/playground-v2.5-1024px-aesthetic.fp16.safetensors\" to /content/DeFooocus/models/checkpoints/playground-v2.5-1024px-aesthetic.fp16.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:18<00:00, 88.5MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/sd1.5.json\n",
            "Loaded preset: /content/DeFooocus/presets/playground_v2.5.json\n",
            "Loaded preset: /content/DeFooocus/presets/sai.json\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0_0.9vae.safetensors\" to /content/DeFooocus/models/checkpoints/sd_xl_base_1.0_0.9vae.safetensors\n",
            "\n",
            "100% 6.46G/6.46G [01:14<00:00, 93.6MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0_0.9vae.safetensors\" to /content/DeFooocus/models/checkpoints/sd_xl_refiner_1.0_0.9vae.safetensors\n",
            "\n",
            "100% 5.66G/5.66G [01:16<00:00, 79.7MB/s]\n",
            "Loaded preset: /content/DeFooocus/presets/lcm.json\n",
            "Loaded preset: /content/DeFooocus/presets/realistic.json\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 6793561165407839805\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Using split attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using split attention in VAE\n",
            "extra {'cond_stage_model.clip_g.transformer.text_model.embeddings.position_ids', 'cond_stage_model.clip_l.text_projection', 'cond_stage_model.clip_l.logit_scale'}\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/DeFooocus/models/checkpoints/realisticStockPhoto_v20.safetensors\n",
            "Request to load LoRAs [['SDXL_FILM_PHOTOGRAPHY_STYLE_BetaV0.4.safetensors', 0.25], ['None', 1.0], ['None', 1.0], ['None', 1.0], ['None', 1.0]] for model [/content/DeFooocus/models/checkpoints/realisticStockPhoto_v20.safetensors].\n",
            "Loaded LoRA [/content/DeFooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_BetaV0.4.safetensors] for UNet [/content/DeFooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 788 keys at weight 0.25.\n",
            "Loaded LoRA [/content/DeFooocus/models/loras/SDXL_FILM_PHOTOGRAPHY_STYLE_BetaV0.4.safetensors] for CLIP [/content/DeFooocus/models/checkpoints/realisticStockPhoto_v20.safetensors] with 264 keys at weight 0.25.\n",
            "Requested to load SDXLClipModel\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.08 seconds\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] دختر لخت کمسن که بدنش کامل در دید عموم هستش, highly detailed, epic composition, magical atmosphere, cinematic, dynamic, vivid, beautiful, light, surreal, symmetry\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1024, 1024)\n",
            "Preparation time: 55.80 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "unload clone 2\n",
            "[Fooocus Model Management] Moving model(s) has taken 2.22 seconds\n",
            "100% 25/25 [00:45<00:00,  1.83s/it]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.25 seconds\n",
            "Image generated with private log at: /content/DeFooocus/outputs/2025-05-14/log.html\n",
            "Generating and saving time: 50.68 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 106.50 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.70 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 2406165777481697790\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] دختر لخت کمسن که بدنش کامل در دید عموم هستش, elegant, highly detailed, magic, sharp focus, radiant light, beautiful, intricate, epic, cinematic, candid\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1408, 704)\n",
            "Preparation time: 1.24 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.04 seconds\n",
            " 36% 9/25 [00:17<00:31,  1.96s/it]\n",
            "User stopped\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 20.00 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.81 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 4306327124132977599\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] دختر لخت کمسن, highly detailed, legendary epic composition, magical atmosphere, cinematic light, sharp focus, elegant, intricate, very coherent, theatrical, fine, romantic, surreal, imposing, iconic, rich deep colors, colorful, rational, artistic, positive, vibrant, symmetry, great, perfect, detail, ambient\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1408, 704)\n",
            "Preparation time: 1.71 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.46 seconds\n",
            " 60% 15/25 [00:28<00:19,  1.92s/it]\n",
            "User stopped\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 31.06 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.68 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 4244954660950568361\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] دختر لخت کمسن, highly detailed, sharp focus, elegant, cinematic, fine composition, intricate, very coherent, colorful, ambient, modern, surreal, epic, magical, striking, imposing, incredible, creative, extremely beautiful, symmetry, illuminated, amazing, singular, flowing, light, colors, perfect, magnificent\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (1408, 704)\n",
            "Preparation time: 1.91 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.53 seconds\n",
            " 56% 14/25 [00:26<00:20,  1.87s/it]\n",
            "User stopped\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 28.58 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.77 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 3.0\n",
            "[Parameters] Seed = 5706526470936397850\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] دو فرد لزبین کمسن ژاپنی در حالی که بدنشون سفیده و در حال مالیدن همدیگه هستند و غرق در اذت های جنسی شده اند, highly detailed, intricate, epic composition, magical atmosphere, cinematic, full color, best light, dynamic background, vivid colors, focus, elegant, shiny, colorful\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (960, 1088)\n",
            "Preparation time: 1.27 seconds\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.47 seconds\n",
            " 24% 6/25 [00:13<00:42,  2.23s/it]\n",
            "User stopped\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 15.17 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.72 seconds\n",
            "Loaded preset: /content/DeFooocus/presets/anime.json\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 7.0\n",
            "[Parameters] Seed = 4832598939912386192\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 901, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 421, in handler\n",
            "    pipeline.refresh_everything(refiner_model_name=refiner_model_name, base_model_name=base_model_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 233, in refresh_everything\n",
            "    refresh_base_model(base_model_name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 69, in refresh_base_model\n",
            "    model_base = core.load_model(filename)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/core.py\", line 145, in load_model\n",
            "    unet, clip, vae, clip_vision = load_checkpoint_guess_config(ckpt_filename, embedding_directory=path_embeddings)\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/sd.py\", line 461, in load_checkpoint_guess_config\n",
            "    model = model_config.get_model(sd, \"model.diffusion_model.\", device=inital_load_device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/supported_models.py\", line 173, in get_model\n",
            "    out = model_base.SDXL(self, model_type=self.model_type(state_dict, prefix), device=device)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 293, in __init__\n",
            "    super().__init__(model_config, model_type, device=device)\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 51, in __init__\n",
            "    self.diffusion_model = UNetModel(**unet_config, device=device, operations=operations)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 773, in __init__\n",
            "    get_attention_layer(\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 556, in get_attention_layer\n",
            "    return SpatialTransformer(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in __init__\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in <listcomp>\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 416, in __init__\n",
            "    self.ff = FeedForward(inner_dim, dim_out=dim, dropout=dropout, glu=gated_ff, dtype=dtype, device=device, operations=operations)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 73, in __init__\n",
            "    ) if not glu else GEGLU(dim, inner_dim, dtype=dtype, device=device, operations=operations)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 58, in __init__\n",
            "    self.proj = operations.Linear(dim_in, dim_out * 2, dtype=dtype, device=device)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 106, in __init__\n",
            "    torch.empty((out_features, in_features), **factory_kwargs)\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 18.12 MiB is free. Process 13953 has 14.72 GiB memory in use. Of the allocated memory 14.38 GiB is allocated by PyTorch, and 214.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Total time: 4.67 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 7.0\n",
            "[Parameters] Seed = 3106841826914815625\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 901, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 421, in handler\n",
            "    pipeline.refresh_everything(refiner_model_name=refiner_model_name, base_model_name=base_model_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 233, in refresh_everything\n",
            "    refresh_base_model(base_model_name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 69, in refresh_base_model\n",
            "    model_base = core.load_model(filename)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/core.py\", line 145, in load_model\n",
            "    unet, clip, vae, clip_vision = load_checkpoint_guess_config(ckpt_filename, embedding_directory=path_embeddings)\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/sd.py\", line 461, in load_checkpoint_guess_config\n",
            "    model = model_config.get_model(sd, \"model.diffusion_model.\", device=inital_load_device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/supported_models.py\", line 173, in get_model\n",
            "    out = model_base.SDXL(self, model_type=self.model_type(state_dict, prefix), device=device)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 293, in __init__\n",
            "    super().__init__(model_config, model_type, device=device)\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 51, in __init__\n",
            "    self.diffusion_model = UNetModel(**unet_config, device=device, operations=operations)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 773, in __init__\n",
            "    get_attention_layer(\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 556, in get_attention_layer\n",
            "    return SpatialTransformer(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in __init__\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in <listcomp>\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 416, in __init__\n",
            "    self.ff = FeedForward(inner_dim, dim_out=dim, dropout=dropout, glu=gated_ff, dtype=dtype, device=device, operations=operations)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 78, in __init__\n",
            "    operations.Linear(inner_dim, dim_out, dtype=dtype, device=device)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 106, in __init__\n",
            "    torch.empty((out_features, in_features), **factory_kwargs)\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 12.12 MiB is free. Process 13953 has 14.73 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 190.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Total time: 1.92 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 7.0\n",
            "[Parameters] Seed = 1456087374228380750\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 901, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 421, in handler\n",
            "    pipeline.refresh_everything(refiner_model_name=refiner_model_name, base_model_name=base_model_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 233, in refresh_everything\n",
            "    refresh_base_model(base_model_name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 69, in refresh_base_model\n",
            "    model_base = core.load_model(filename)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/core.py\", line 145, in load_model\n",
            "    unet, clip, vae, clip_vision = load_checkpoint_guess_config(ckpt_filename, embedding_directory=path_embeddings)\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/sd.py\", line 461, in load_checkpoint_guess_config\n",
            "    model = model_config.get_model(sd, \"model.diffusion_model.\", device=inital_load_device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/supported_models.py\", line 173, in get_model\n",
            "    out = model_base.SDXL(self, model_type=self.model_type(state_dict, prefix), device=device)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 293, in __init__\n",
            "    super().__init__(model_config, model_type, device=device)\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 51, in __init__\n",
            "    self.diffusion_model = UNetModel(**unet_config, device=device, operations=operations)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 773, in __init__\n",
            "    get_attention_layer(\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 556, in get_attention_layer\n",
            "    return SpatialTransformer(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in __init__\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in <listcomp>\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 416, in __init__\n",
            "    self.ff = FeedForward(inner_dim, dim_out=dim, dropout=dropout, glu=gated_ff, dtype=dtype, device=device, operations=operations)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 78, in __init__\n",
            "    operations.Linear(inner_dim, dim_out, dtype=dtype, device=device)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 106, in __init__\n",
            "    torch.empty((out_features, in_features), **factory_kwargs)\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 12.12 MiB is free. Process 13953 has 14.73 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 190.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Total time: 1.86 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 3173853675307031271\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 901, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 421, in handler\n",
            "    pipeline.refresh_everything(refiner_model_name=refiner_model_name, base_model_name=base_model_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 233, in refresh_everything\n",
            "    refresh_base_model(base_model_name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 69, in refresh_base_model\n",
            "    model_base = core.load_model(filename)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/core.py\", line 145, in load_model\n",
            "    unet, clip, vae, clip_vision = load_checkpoint_guess_config(ckpt_filename, embedding_directory=path_embeddings)\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/sd.py\", line 461, in load_checkpoint_guess_config\n",
            "    model = model_config.get_model(sd, \"model.diffusion_model.\", device=inital_load_device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/supported_models.py\", line 173, in get_model\n",
            "    out = model_base.SDXL(self, model_type=self.model_type(state_dict, prefix), device=device)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 293, in __init__\n",
            "    super().__init__(model_config, model_type, device=device)\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 51, in __init__\n",
            "    self.diffusion_model = UNetModel(**unet_config, device=device, operations=operations)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 773, in __init__\n",
            "    get_attention_layer(\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 556, in get_attention_layer\n",
            "    return SpatialTransformer(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in __init__\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in <listcomp>\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 416, in __init__\n",
            "    self.ff = FeedForward(inner_dim, dim_out=dim, dropout=dropout, glu=gated_ff, dtype=dtype, device=device, operations=operations)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 78, in __init__\n",
            "    operations.Linear(inner_dim, dim_out, dtype=dtype, device=device)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 106, in __init__\n",
            "    torch.empty((out_features, in_features), **factory_kwargs)\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 12.12 MiB is free. Process 13953 has 14.73 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 190.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Total time: 2.89 seconds\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] CFG = 4.0\n",
            "[Parameters] Seed = 5085128694768198593\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 25 - 12\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 901, in worker\n",
            "    handler(task)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/async_worker.py\", line 421, in handler\n",
            "    pipeline.refresh_everything(refiner_model_name=refiner_model_name, base_model_name=base_model_name,\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 233, in refresh_everything\n",
            "    refresh_base_model(base_model_name)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/default_pipeline.py\", line 69, in refresh_base_model\n",
            "    model_base = core.load_model(filename)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/modules/core.py\", line 145, in load_model\n",
            "    unet, clip, vae, clip_vision = load_checkpoint_guess_config(ckpt_filename, embedding_directory=path_embeddings)\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/sd.py\", line 461, in load_checkpoint_guess_config\n",
            "    model = model_config.get_model(sd, \"model.diffusion_model.\", device=inital_load_device)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/supported_models.py\", line 173, in get_model\n",
            "    out = model_base.SDXL(self, model_type=self.model_type(state_dict, prefix), device=device)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 293, in __init__\n",
            "    super().__init__(model_config, model_type, device=device)\n",
            "  File \"/content/DeFooocus/ldm_patched/modules/model_base.py\", line 51, in __init__\n",
            "    self.diffusion_model = UNetModel(**unet_config, device=device, operations=operations)\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 773, in __init__\n",
            "    get_attention_layer(\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 556, in get_attention_layer\n",
            "    return SpatialTransformer(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in __init__\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 586, in <listcomp>\n",
            "    [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim[d],\n",
            "     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 416, in __init__\n",
            "    self.ff = FeedForward(inner_dim, dim_out=dim, dropout=dropout, glu=gated_ff, dtype=dtype, device=device, operations=operations)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/DeFooocus/ldm_patched/ldm/modules/attention.py\", line 78, in __init__\n",
            "    operations.Linear(inner_dim, dim_out, dtype=dtype, device=device)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 106, in __init__\n",
            "    torch.empty((out_features, in_features), **factory_kwargs)\n",
            "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 12.12 MiB is free. Process 13953 has 14.73 GiB memory in use. Of the allocated memory 14.41 GiB is allocated by PyTorch, and 190.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "Total time: 1.87 seconds\n"
          ]
        }
      ],
      "source": [
        "#@title DeFooocus\n",
        "#@markdown **Launch the interface DeFocus (Fooocus fork)** | You need to connect with T4/A100/V100\n",
        "#@markdown ****\n",
        "#@markdown *Attention!* When working in the interface with the FaceSwap and CPDS controlnet, crashes are possible; it is also recommended to work in *Extreme speed* mode for additional stability. When working with the ImagePrompt and PyraCanny controls, 85% of the work will be stable.\n",
        "#@markdown ****\n",
        "\n",
        "print(\"[DeFooocus] Preparing ...\")\n",
        "\n",
        "theme = \"dark\" #@param [\"dark\", \"light\"]\n",
        "preset = \"deafult\" #@param [\"deafult\", \"realistic\", \"anime\", \"lcm\", \"sai\", \"turbo\", \"lighting\", \"hypersd\", \"playground_v2.5\", \"dpo\", \"spo\", \"sd1.5\"]\n",
        "advenced_args = \"--share --attention-split --always-high-vram --disable-offload-from-vram --all-in-fp16\" #@param {type: \"string\"}\n",
        "\n",
        "if preset != \"deafult\":\n",
        "  args = f\"{advenced_args} --theme {theme} --preset {preset}\"\n",
        "else:\n",
        "  args = f\"{advenced_args} --theme {theme}\"\n",
        "\n",
        "!pip install -q pygit2==1.12.2\n",
        "%cd /content\n",
        "!git clone https://github.com/ehristoforu/DeFooocus.git\n",
        "%cd /content/DeFooocus\n",
        "!pip install -q -r requirements_versions.txt\n",
        "\n",
        "print(\"[DeFooocus] Starting ...\")\n",
        "!python entry_with_update.py $args"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}